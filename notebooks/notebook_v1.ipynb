{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3fc097b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eadcb4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim==3.8.1 in c:\\users\\phuckmanity\\ds\\sentiment_analysis_hausa\\venv\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\phuckmanity\\ds\\sentiment_analysis_hausa\\venv\\lib\\site-packages (from gensim==3.8.1) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\phuckmanity\\ds\\sentiment_analysis_hausa\\venv\\lib\\site-packages (from gensim==3.8.1) (1.19.5)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\phuckmanity\\ds\\sentiment_analysis_hausa\\venv\\lib\\site-packages (from gensim==3.8.1) (5.2.1)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\phuckmanity\\ds\\sentiment_analysis_hausa\\venv\\lib\\site-packages (from gensim==3.8.1) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim==3.8.1\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7680b9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created `%t` as an alias for `%timeit`.\n",
      "Created `%%t` as an alias for `%%timeit`.\n"
     ]
    }
   ],
   "source": [
    "# core system imports\n",
    "import os\n",
    "\n",
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import string\n",
    "import random\n",
    "from unidecode import unidecode\n",
    "import itertools\n",
    "from timeit import timeit\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, \n",
    "    Input, \n",
    "    LSTM, \n",
    "    Embedding, \n",
    "    Dropout, \n",
    "    Activation, \n",
    "    Bidirectional, \n",
    "    GlobalMaxPool1D\n",
    ")\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import (\n",
    "    initializers, \n",
    "    regularizers, \n",
    "    constraints, \n",
    "    optimizers, \n",
    "    layers\n",
    ")\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support\n",
    ")\n",
    "\n",
    "# Matplotlib config\n",
    "%matplotlib inline\n",
    "%alias_magic t timeit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aad9ccbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d934d04",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '../input'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\PHUCKM~1\\AppData\\Local\\Temp/ipykernel_11924/2388156987.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Input data is available in the \"../input/\" directory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '../input'"
     ]
    }
   ],
   "source": [
    "# Input data is available in the \"../input/\" directory\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fe767c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of the pipeline metadata store\n",
    "_pipeline_root = './pipeline/'\n",
    "\n",
    "# Directory of the raw data files\n",
    "_data_root = './data/hausa'\n",
    "\n",
    "_data_filepath = os.path.join(_data_root, \"data.csv\")\n",
    "_stopwords_filepath = os.path.join(_data_root, \"stopwords.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c70a3c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data.csv', 'stopwords.txt']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List datasets in directory\n",
    "os.listdir(_data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe9bed6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author_id</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- @aishambuhari ta nemi babban sufeton 'yan sa...</td>\n",
       "      <td>7.970000e+17</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Duk dan Bokon da baida Ilimin Addini Annoba n...</td>\n",
       "      <td>2.290470e+09</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Duk mutumin da yayi tunanin bawa mutane ilimi...</td>\n",
       "      <td>1.071387e+09</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Duk wanda ya sabawa dokar kaucewa kamuwa daga...</td>\n",
       "      <td>1.260000e+18</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Duk wanda ya san ya fito daga yankin da ake A...</td>\n",
       "      <td>1.039268e+09</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     author_id     Label\n",
       "0  - @aishambuhari ta nemi babban sufeton 'yan sa...  7.970000e+17   Neutral\n",
       "1  \"Duk dan Bokon da baida Ilimin Addini Annoba n...  2.290470e+09   Neutral\n",
       "2  \"Duk mutumin da yayi tunanin bawa mutane ilimi...  1.071387e+09   Neutral\n",
       "3  \"Duk wanda ya sabawa dokar kaucewa kamuwa daga...  1.260000e+18  Positive\n",
       "4  \"Duk wanda ya san ya fito daga yankin da ake A...  1.039268e+09  Positive"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data from CSV file\n",
    "data = pd.read_csv(_data_filepath)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c6be05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read stop words\n",
    "stopwords_list = list()\n",
    "\n",
    "with open(_stopwords_filepath) as file:\n",
    "    stopwords_list = [line.strip() for line in file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6400176a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ta da ya sai ba yi na kuma ma ji cikin in ni wata wani ce tana don za sun amma ga ina ne mai suka wannan a ko lokacin su take shi yake yana ka ban ita tafi\n"
     ]
    }
   ],
   "source": [
    "listToStr = ' '.join([str(word) for word in stopwords_list])\n",
    "print(listToStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef00641c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing stopwords\n",
    "def _apply_lowercase(text):\n",
    "    text = [item for item in text if item not in stopwords_list]\n",
    "    text = ''.join(text)\n",
    "    return text\n",
    "\n",
    "# removing stopwords\n",
    "def _stopwords_removal(text):\n",
    "    text = [item for item in text if item not in stopwords_list]\n",
    "    text = ''.join(text)\n",
    "    return text\n",
    "\n",
    "# remove punctuations\n",
    "def _punctuation_removal(text):\n",
    "    all_list = [char for char in text if char not in string.punctuation]\n",
    "    clean_str = ''.join(all_list)\n",
    "    return clean_str\n",
    "\n",
    "# Shuffle dataset\n",
    "def _shuffle_dataset(dataset):\n",
    "    dataset = shuffle(data)\n",
    "    dataset = data.reset_index(drop=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5f914d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author_id</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ishmbuhri t nemi bbbn sufeton yn snd d y mgnc...</td>\n",
       "      <td>7.970000e+17</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>duk dn bokon d bid ilimin ddini nnob ne cikin ...</td>\n",
       "      <td>2.290470e+09</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>duk mutumin d yyi tunnin bw mutne ilimi d koy ...</td>\n",
       "      <td>1.071387e+09</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>duk wnd y sbw dokr kucew kmuw dg cutr coron zi...</td>\n",
       "      <td>1.260000e+18</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>duk wnd y sn y fito dg ynkin d ke nnobr coron ...</td>\n",
       "      <td>1.039268e+09</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     author_id     Label\n",
       "0   ishmbuhri t nemi bbbn sufeton yn snd d y mgnc...  7.970000e+17   Neutral\n",
       "1  duk dn bokon d bid ilimin ddini nnob ne cikin ...  2.290470e+09   Neutral\n",
       "2  duk mutumin d yyi tunnin bw mutne ilimi d koy ...  1.071387e+09   Neutral\n",
       "3  duk wnd y sbw dokr kucew kmuw dg cutr coron zi...  1.260000e+18  Positive\n",
       "4  duk wnd y sn y fito dg ynkin d ke nnobr coron ...  1.039268e+09  Positive"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change string to lower case\n",
    "data['text'] = data['text'].apply(str.lower)\n",
    "\n",
    "# remove punctuations or special characters\n",
    "data['text'] = data['text'].apply(_punctuation_removal)\n",
    "\n",
    "# remove stopwords\n",
    "data['text'] = data['text'].apply(_stopwords_removal)\n",
    "\n",
    "# Shuffle the dataset to prevent bias:\n",
    "data = _shuffle_dataset(data)\n",
    "\n",
    "# Print head of the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb7733e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711dbd89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf692cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
