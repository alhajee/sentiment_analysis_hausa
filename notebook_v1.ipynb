{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3fc097b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eadcb4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim==3.8.1 in c:\\users\\phuckmanity\\ds\\sentiment_analysis_hausa\\venv\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\phuckmanity\\ds\\sentiment_analysis_hausa\\venv\\lib\\site-packages (from gensim==3.8.1) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\phuckmanity\\ds\\sentiment_analysis_hausa\\venv\\lib\\site-packages (from gensim==3.8.1) (1.19.5)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\phuckmanity\\ds\\sentiment_analysis_hausa\\venv\\lib\\site-packages (from gensim==3.8.1) (5.2.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\phuckmanity\\ds\\sentiment_analysis_hausa\\venv\\lib\\site-packages (from gensim==3.8.1) (1.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim==3.8.1\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7680b9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created `%t` as an alias for `%timeit`.\n",
      "Created `%%t` as an alias for `%%timeit`.\n"
     ]
    }
   ],
   "source": [
    "# core system imports\n",
    "import os\n",
    "\n",
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import string\n",
    "import random\n",
    "from unidecode import unidecode\n",
    "import itertools\n",
    "from timeit import timeit\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, \n",
    "    Input, \n",
    "    LSTM, \n",
    "    Embedding, \n",
    "    Dropout, \n",
    "    Activation, \n",
    "    Bidirectional, \n",
    "    GlobalMaxPool1D\n",
    ")\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import (\n",
    "    initializers, \n",
    "    regularizers, \n",
    "    constraints, \n",
    "    optimizers, \n",
    "    layers\n",
    ")\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support\n",
    ")\n",
    "\n",
    "# Matplotlib config\n",
    "%matplotlib inline\n",
    "%alias_magic t timeit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aad9ccbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4fe767c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of the pipeline metadata store\n",
    "_pipeline_root = './pipeline/'\n",
    "\n",
    "# Directory of the raw data files\n",
    "_data_root = './data/hausa'\n",
    "\n",
    "_data_filepath = os.path.join(_data_root, \"data.csv\")\n",
    "_stopwords_filepath = os.path.join(_data_root, \"stopwords.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c70a3c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data.csv', 'stopwords.txt']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List datasets in directory\n",
    "os.listdir(_data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fe9bed6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author_id</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- @aishambuhari ta nemi babban sufeton 'yan sa...</td>\n",
       "      <td>7.970000e+17</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Duk dan Bokon da baida Ilimin Addini Annoba n...</td>\n",
       "      <td>2.290470e+09</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Duk mutumin da yayi tunanin bawa mutane ilimi...</td>\n",
       "      <td>1.071387e+09</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Duk wanda ya sabawa dokar kaucewa kamuwa daga...</td>\n",
       "      <td>1.260000e+18</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Duk wanda ya san ya fito daga yankin da ake A...</td>\n",
       "      <td>1.039268e+09</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     author_id     Label\n",
       "0  - @aishambuhari ta nemi babban sufeton 'yan sa...  7.970000e+17   Neutral\n",
       "1  \"Duk dan Bokon da baida Ilimin Addini Annoba n...  2.290470e+09   Neutral\n",
       "2  \"Duk mutumin da yayi tunanin bawa mutane ilimi...  1.071387e+09   Neutral\n",
       "3  \"Duk wanda ya sabawa dokar kaucewa kamuwa daga...  1.260000e+18  Positive\n",
       "4  \"Duk wanda ya san ya fito daga yankin da ake A...  1.039268e+09  Positive"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data from CSV file\n",
    "data = pd.read_csv(_data_filepath)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9c6be05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read stop words\n",
    "stopwords_list = list()\n",
    "\n",
    "with open(_stopwords_filepath) as file:\n",
    "    stopwords_list = [line.strip() for line in file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6400176a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ta da ya sai ba yi na kuma ma ji cikin in ni wata wani ce tana don za sun amma ga ina ne mai suka wannan a ko lokacin su take shi yake yana ka ban ita tafi\n"
     ]
    }
   ],
   "source": [
    "listToStr = ' '.join([str(word) for word in stopwords_list])\n",
    "print(listToStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ef00641c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing stopwords\n",
    "def _apply_lowercase(text):\n",
    "    text = [item for item in text if item not in stopwords_list]\n",
    "    text = ''.join(text)\n",
    "    return text\n",
    "\n",
    "# removing stopwords\n",
    "def _stopwords_removal(text):\n",
    "    text = [item for item in text if item not in stopwords_list]\n",
    "    text = ''.join(text)\n",
    "    return text\n",
    "\n",
    "# remove punctuations\n",
    "def _punctuation_removal(text):\n",
    "    all_list = [char for char in text if char not in string.punctuation]\n",
    "    clean_str = ''.join(all_list)\n",
    "    return clean_str\n",
    "\n",
    "# Shuffle dataset\n",
    "def _shuffle_dataset(dataset):\n",
    "    dataset = shuffle(data)\n",
    "    dataset = data.reset_index(drop=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c5f914d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author_id</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>msllci ko bbu nnob tun sli wje ne mi tsri d sn...</td>\n",
       "      <td>1.665774e+09</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kdunvskno kd guys yi hkuri  zun gid  wnke hnnu...</td>\n",
       "      <td>1.112804e+09</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hydr313 mlm hydr wi in nufin mu ynzu b bund y ...</td>\n",
       "      <td>1.060000e+18</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lkliehjr sddheeck  wnke hnnu ske wnkew</td>\n",
       "      <td>9.290000e+17</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hfstpki yshersdiq kwi kr hkuri  zun gid  dink ...</td>\n",
       "      <td>8.140000e+17</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     author_id     Label\n",
       "0  msllci ko bbu nnob tun sli wje ne mi tsri d sn...  1.665774e+09   Neutral\n",
       "1  kdunvskno kd guys yi hkuri  zun gid  wnke hnnu...  1.112804e+09  Positive\n",
       "2  hydr313 mlm hydr wi in nufin mu ynzu b bund y ...  1.060000e+18  Positive\n",
       "3             lkliehjr sddheeck  wnke hnnu ske wnkew  9.290000e+17  Positive\n",
       "4  hfstpki yshersdiq kwi kr hkuri  zun gid  dink ...  8.140000e+17  Positive"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change string to lower case\n",
    "data['text'] = data['text'].apply(str.lower)\n",
    "\n",
    "# remove punctuations or special characters\n",
    "data['text'] = data['text'].apply(_punctuation_removal)\n",
    "\n",
    "# remove stopwords\n",
    "data['text'] = data['text'].apply(_stopwords_removal)\n",
    "\n",
    "# Shuffle the dataset to prevent bias:\n",
    "data = _shuffle_dataset(data)\n",
    "\n",
    "# Print head of the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fdb7733e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711dbd89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf692cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
